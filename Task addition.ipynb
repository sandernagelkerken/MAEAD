{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.MAE import *\n",
    "import pickle\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "import torch\n",
    "import copy\n",
    "from functions.benchmark import *\n",
    "n_tasks = 4\n",
    "combinations = pickle.load(open(f\"C:\\LocalData\\Code\\Thesis\\evaluation_data\\Test_combinations_{n_tasks}.pkl\", \"rb\"))\n",
    "test_data = pickle.load(open(f\"evaluation_data\\Test_data_{n_tasks}_100.pkl\",\"rb\"))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "eval_loss_function= torch.nn.MSELoss\n",
    "optimizer = torch.optim.RAdam\n",
    "train_loss_function = torch.nn.SmoothL1Loss\n",
    "cols = [str(i) for i in np.arange(0,300,1)]\n",
    "from functions.evaluation import evaluate_on_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vanilla_MAE(nn.Module):\n",
    "    def __init__(self, encoding_size, sequence_length, combinations, n_hidden_layers, hidden_size:int = -1, n_variable_layers:int = -1):\n",
    "        super(Vanilla_MAE, self).__init__()                                     \n",
    "        self.encoding_size = encoding_size\n",
    "        self.sequence_length = sequence_length                                  \n",
    "        self.combinations = combinations\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_variable_layers = n_variable_layers\n",
    "        self.task_IDs = []\n",
    "        if self.n_hidden_layers == 0:\n",
    "            self.fixed = nn.Sequential(nn.Linear(self.sequence_length, self.encoding_size),\n",
    "                                       nn.ReLU())                               \n",
    "            self.variable = nn.ModuleDict()                                     \n",
    "            for shifting_type in combinations:                                  \n",
    "                for transformer_ID in combinations[shifting_type]:\n",
    "                    combination_ID = combination_to_id(shifting_type,transformer_ID, self.combinations)\n",
    "                    self.task_IDs.append(int(combination_ID))\n",
    "                    self.variable[str(combination_ID)] = nn.Linear(self.encoding_size, self.sequence_length)   \n",
    "        elif self.n_hidden_layers == 1:\n",
    "            if hidden_size == -1:\n",
    "                raise ValueError(\"Choose a hidden size\")\n",
    "            elif hidden_size < 1:\n",
    "                raise ValueError(\"Choose a positive hidden size\")\n",
    "            if self.n_variable_layers == 1:\n",
    "                self.fixed = nn.Sequential(nn.Linear(self.sequence_length, self.hidden_size), \n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(self.hidden_size, self.encoding_size),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(self.encoding_size, self.hidden_size),\n",
    "                                        nn.ReLU())\n",
    "                self.variable = nn.ModuleDict()                                         \n",
    "                for shifting_type in combinations:                              \n",
    "                    for transformer_ID in combinations[shifting_type]:\n",
    "                        combination_ID = combination_to_id(shifting_type,transformer_ID, combinations) \n",
    "                        self.variable[str(combination_ID)] = nn.Linear(self.hidden_size, self.sequence_length)\n",
    "            elif self.n_variable_layers == 2:\n",
    "                self.fixed = nn.Sequential(nn.Linear(self.sequence_length, self.hidden_size),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(self.hidden_size, self.encoding_size),\n",
    "                                        nn.ReLU())\n",
    "                self.variable = nn.ModuleDict()                                     \n",
    "                for shifting_type in combinations:                                  \n",
    "                    for transformer_ID in combinations[shifting_type]:\n",
    "                        combination_ID = combination_to_id(shifting_type,transformer_ID, combinations)\n",
    "                        self.variable[str(combination_ID)] = nn.Sequential(nn.Linear(self.encoding_size, self.hidden_size),\n",
    "                                                                    nn.ReLU(),\n",
    "                                                                    nn.Linear(self.hidden_size, self.sequence_length)) \n",
    "            else:\n",
    "                raise NotImplementedError(\"Please choose between 1 or 2 variable layers.\")\n",
    "        else:\n",
    "            raise NotImplementedError(\"Please choose between 0 or 1 hidden layers.\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_id = x[:,self.sequence_length]\n",
    "        sort = torch.argsort(x_id)\n",
    "        reversesort = torch.argsort(sort)\n",
    "        x = x[sort]\n",
    "        y = []\n",
    "        ids = torch.unique(x[:,self.sequence_length],sorted=False)\n",
    "        for i in ids:\n",
    "            x_i = x[x[:,self.sequence_length] == i]\n",
    "            if x_i.shape[0] != 0:\n",
    "                combination_ID = str(int(x_i[0,self.sequence_length].item()))\n",
    "                x_i = x_i[:,:self.sequence_length]                           \n",
    "                x_i = self.fixed(x_i)                                  \n",
    "                x_i = self.variable[combination_ID](x_i)                         \n",
    "                y.append(x_i)\n",
    "        x = torch.concat(y,0)\n",
    "        x = x[reversesort]\n",
    "        return x\n",
    "    \n",
    "    def add_task(self, task_ID, shifting_type, transformer_ID, num_epochs, instances:int = 987654321, lr_schedule:bool = False, schedule_milestones = [60,90], convergence_plot:bool = True, return_training_loss:bool = True, path=\"C:\\LocalData\\Data\\Completely_preprocessed_data\"):\n",
    "        if task_ID in self.task_IDs:\n",
    "            raise ValueError(\"Task ID already used, please choose an unused task ID\")\n",
    "        if self.n_hidden_layers == 0:                                  \n",
    "            self.variable[str(task_ID)] = nn.Linear(self.encoding_size, self.sequence_length)   \n",
    "        elif self.n_hidden_layers == 1:\n",
    "            if self.n_variable_layers == 1:\n",
    "                self.variable[str(task_ID)] = nn.Linear(self.hidden_size, self.sequence_length)\n",
    "            elif self.n_variable_layers == 2:\n",
    "                self.variable[str(task_ID)] = nn.Sequential(nn.Linear(self.encoding_size, self.hidden_size),\n",
    "                                                                    nn.ReLU(),\n",
    "                                                                    nn.Linear(self.hidden_size, self.sequence_length))\n",
    "        ds = create_dataset({shifting_type : {transformer_ID : task_ID}}, [str(i) for i in np.arange(0,300,1)], path)\n",
    "        if instances != 987654321:\n",
    "            ds.df_torque = ds.df_torque.sample(instances, replace=True)\n",
    "        dl = torch.utils.data.DataLoader(ds, 64, True)\n",
    "        for param in self.fixed.parameters():\n",
    "            param.requires_grad = False\n",
    "        loss_function = nn.SmoothL1Loss()\n",
    "        optimizer = optim.Adam(self.variable.parameters(), 0.0001)\n",
    "        if lr_schedule:\n",
    "            scheduler = MultiStepLR(optimizer, milestones=schedule_milestones, gamma=0.1)\n",
    "        losses = []\n",
    "        for epoch in tqdm(range(num_epochs),leave=None):\n",
    "            last_losses = []\n",
    "            for data in dl:\n",
    "                data= data.to(device=device)                                        #Bring the data onto the device\n",
    "                reconstruction = self.forward(data)                                        #Execute the model\n",
    "                loss = loss_function(reconstruction, data[:,:self.sequence_length])      #Compute the loss\n",
    "                optimizer.zero_grad()                                               #Set the gradients to 0 for each batch\n",
    "                loss.backward()                                                     #Compute gradients using backpropagation\n",
    "                optimizer.step()                                                    #Execute parameter updates\n",
    "                losses.append(loss.data)\n",
    "                last_losses.append(loss.data)\n",
    "            if lr_schedule:\n",
    "                scheduler.step()\n",
    "        if convergence_plot:                                                        #Optionally plot the convergence over the iterations\n",
    "            plt.xlabel(\"Batch\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.ylim(top = 20)\n",
    "            plt.plot(torch.Tensor(losses).cpu(), linewidth = 0.2, color = \"black\")\n",
    "            plt.show()\n",
    "        self.task_IDs.append(task_ID)\n",
    "        if return_training_loss:\n",
    "            return torch.mean(torch.Tensor(losses).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCN_MAE(nn.Module):\n",
    "    def __init__(self, sequence_length, combinations, n_channels:int, n_channels_reduced:int, n_encoding_channels:int, n_variable_layers:int, device, kernel_size:int = 5, pool_rate:int = 2, num_layers:int = 6):\n",
    "        super(TCN_MAE, self).__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "        self.combinations = combinations\n",
    "        self.n_channels = n_channels\n",
    "        self.n_channels_reduced = n_channels_reduced\n",
    "        self.n_encoding_channels = n_encoding_channels\n",
    "        self.pool_rate = pool_rate\n",
    "        self.n_variable_layers = n_variable_layers\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_layers = num_layers\n",
    "        self.device = device\n",
    "        self.task_IDs = []\n",
    "        self.encoder = nn.ModuleDict()\n",
    "        for i in range(num_layers):\n",
    "            if i == 0:\n",
    "                self.encoder[str(i)] = nn.Sequential(nn.Conv1d(1, self.n_channels, self.kernel_size,padding = 'same', dilation = 2**i),\n",
    "                                                     nn.ReLU(),\n",
    "                                                     nn.Conv1d(self.n_channels, self.n_channels_reduced, 1),\n",
    "                                                     nn.ReLU())\n",
    "            else:\n",
    "                self.encoder[str(i)] = nn.Sequential(nn.Conv1d(self.n_channels_reduced, self.n_channels, self.kernel_size,padding = 'same', dilation = 2**i),\n",
    "                                                     nn.ReLU(),\n",
    "                                                     nn.Conv1d(self.n_channels, self.n_channels_reduced, 1),\n",
    "                                                     nn.ReLU())\n",
    "        self.encoder[\"compressor\"] = nn.Sequential(nn.Conv1d(self.n_channels_reduced*self.num_layers, self.n_encoding_channels, 1),\n",
    "                                                   nn.AvgPool1d(self.pool_rate))\n",
    "        self.decoder_fixed = nn.ModuleDict()\n",
    "        for i in range(self.num_layers - self.n_variable_layers):\n",
    "            if i == 0:\n",
    "                self.decoder_fixed[str(i)] = nn.Sequential(nn.Conv1d(self.n_encoding_channels, self.n_channels, self.kernel_size, dilation=2**(self.num_layers-1-i), padding = 'same'),\n",
    "                                                           nn.ReLU(),\n",
    "                                                           nn.Conv1d(self.n_channels, self.n_channels_reduced, 1),\n",
    "                                                           nn.ReLU())\n",
    "            else:\n",
    "                self.decoder_fixed[str(i)] = nn.Sequential(nn.Conv1d(self.n_channels_reduced, self.n_channels, self.kernel_size, dilation=2**(self.num_layers-1-i), padding = 'same'),\n",
    "                                                           nn.ReLU(),\n",
    "                                                           nn.Conv1d(self.n_channels, self.n_channels_reduced, 1),\n",
    "                                                           nn.ReLU())\n",
    "        self.decoder_variable = nn.ModuleDict()\n",
    "        for shifting_type in combinations:                                      \n",
    "            for transformer_ID in combinations[shifting_type]:\n",
    "                combination_ID = combination_to_id(shifting_type,transformer_ID, combinations) \n",
    "                self.task_IDs.append(str(combination_ID))\n",
    "                self.decoder_variable[str(combination_ID)] = nn.ModuleDict()\n",
    "                for i in range(self.num_layers - self.n_variable_layers, self.num_layers):\n",
    "                    if i == 0:\n",
    "                        self.decoder_variable[str(combination_ID)][str(i)] = nn.Sequential(nn.Conv1d(self.n_encoding_channels, self.n_channels, self.kernel_size, dilation=2**(self.num_layers-1-i), padding = 'same'),\n",
    "                                                                                        nn.ReLU(),\n",
    "                                                                                        nn.Conv1d(self.n_channels, self.n_channels_reduced, 1),\n",
    "                                                                                        nn.ReLU())\n",
    "                    else:\n",
    "                        self.decoder_variable[str(combination_ID)][str(i)] = nn.Sequential(nn.Conv1d(self.n_channels_reduced, self.n_channels, self.kernel_size, dilation=2**(self.num_layers-1-i), padding = 'same'),\n",
    "                                                                                        nn.ReLU(),\n",
    "                                                                                        nn.Conv1d(self.n_channels, self.n_channels_reduced, 1),\n",
    "                                                                                        nn.ReLU())\n",
    "                self.decoder_variable[str(combination_ID)][\"compressor\"] = nn.Conv1d(self.n_channels_reduced*self.num_layers, 1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = []\n",
    "        ids = torch.unique(x[:,self.sequence_length],sorted=False)\n",
    "        for i in ids:\n",
    "            x_i = x[x[:,self.sequence_length] == i]\n",
    "            if x_i.shape[0] != 0:\n",
    "                combination_ID = str(int(x_i[0,self.sequence_length].item()))    #Read the combination ID of first element of the batch\n",
    "                x_i = x_i[:,:self.sequence_length] \n",
    "                x_i = x_i.unsqueeze(1)\n",
    "                encoding = torch.empty(0).to(self.device)\n",
    "                for j in range(self.num_layers):\n",
    "                    x_i = self.encoder[str(j)](x_i)\n",
    "                    encoding = torch.cat((encoding, x_i), dim = 1)\n",
    "                encoding = self.encoder[\"compressor\"](encoding)\n",
    "                x_i = F.interpolate(encoding, self.sequence_length)\n",
    "                decoding = torch.empty(0).to(self.device)\n",
    "                for j in range(self.num_layers - self.n_variable_layers):\n",
    "                    x_i = self.decoder_fixed[str(j)](x_i)\n",
    "                    decoding = torch.cat((decoding, x_i), dim = 1)\n",
    "                for j in range(self.num_layers - self.n_variable_layers, self.num_layers):\n",
    "                    x_i = self.decoder_variable[str(combination_ID)][str(j)](x_i)\n",
    "                    decoding = torch.cat((decoding, x_i), dim = 1)\n",
    "                x_i = self.decoder_variable[str(combination_ID)][\"compressor\"](decoding)\n",
    "                y.append(x_i)\n",
    "        x = torch.concat(y,0)\n",
    "        x = x.squeeze(1)\n",
    "        return x\n",
    "    \n",
    "    def add_task(self, task_ID, shifting_type, transformer_ID, num_epochs, instances:int = 987654321, lr_schedule:bool = False, schedule_milestones = [60,90], convergence_plot:bool = True, return_training_loss:bool = True, path=\"C:\\LocalData\\Data\\Completely_preprocessed_data\"):\n",
    "        if task_ID in self.task_IDs:\n",
    "            raise ValueError(\"Task ID already used, please choose an unused task ID\")\n",
    "        self.decoder_variable[str(task_ID)] = nn.ModuleDict()\n",
    "        for i in range(self.num_layers - self.n_variable_layers, self.num_layers):\n",
    "            if i == 0:\n",
    "                self.decoder_variable[str(task_ID)][str(i)] = nn.Sequential(nn.Conv1d(self.n_encoding_channels, self.n_channels, self.kernel_size, dilation=2**(self.num_layers-1-i), padding = 'same'),\n",
    "                                                                                nn.ReLU(),\n",
    "                                                                                nn.Conv1d(self.n_channels, self.n_channels_reduced, 1),\n",
    "                                                                                nn.ReLU())\n",
    "            else:\n",
    "                self.decoder_variable[str(task_ID)][str(i)] = nn.Sequential(nn.Conv1d(self.n_channels_reduced, self.n_channels, self.kernel_size, dilation=2**(self.num_layers-1-i), padding = 'same'),\n",
    "                                                                                nn.ReLU(),\n",
    "                                                                                nn.Conv1d(self.n_channels, self.n_channels_reduced, 1),\n",
    "                                                                                nn.ReLU())\n",
    "                self.decoder_variable[str(task_ID)][\"compressor\"] = nn.Conv1d(self.n_channels_reduced*self.num_layers, 1, 1)        \n",
    "        ds = create_dataset({shifting_type : {transformer_ID : task_ID}}, [str(i) for i in np.arange(0,300,1)], path)\n",
    "        if instances != 987654321:\n",
    "            ds.df_torque = ds.df_torque.sample(instances, replace=True)\n",
    "        dl = torch.utils.data.DataLoader(ds, 64, True)\n",
    "        for param in self.fixed.parameters():\n",
    "            param.requires_grad = False\n",
    "        loss_function = nn.SmoothL1Loss()\n",
    "        optimizer = optim.Adam(self.variable.parameters(), 0.0001)\n",
    "        if lr_schedule:\n",
    "            scheduler = MultiStepLR(optimizer, milestones=schedule_milestones, gamma=0.1)\n",
    "        losses = []\n",
    "        for epoch in tqdm(range(num_epochs),leave=None):\n",
    "            last_losses = []\n",
    "            for data in dl:\n",
    "                data= data.to(device=device)                                        #Bring the data onto the device\n",
    "                reconstruction = self.forward(data)                                        #Execute the model\n",
    "                loss = loss_function(reconstruction, data[:,:self.sequence_length])      #Compute the loss\n",
    "                optimizer.zero_grad()                                               #Set the gradients to 0 for each batch\n",
    "                loss.backward()                                                     #Compute gradients using backpropagation\n",
    "                optimizer.step()                                                    #Execute parameter updates\n",
    "                losses.append(loss.data)\n",
    "                last_losses.append(loss.data)\n",
    "            if lr_schedule:\n",
    "                scheduler.step()\n",
    "        if convergence_plot:                                                        #Optionally plot the convergence over the iterations\n",
    "            plt.xlabel(\"Batch\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.ylim(top = 20)\n",
    "            plt.plot(torch.Tensor(losses).cpu(), linewidth = 0.2, color = \"black\")\n",
    "            plt.show()\n",
    "        self.task_IDs.append(task_ID)\n",
    "        if return_training_loss:\n",
    "            return torch.mean(torch.Tensor(losses).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_MAE(nn.Module):\n",
    "    def __init__(self, encoding_size, sequence_length, combinations, device, teacher_forcing:bool = True):\n",
    "        super(LSTM_MAE, self).__init__()                        \n",
    "        self.encoding_size = encoding_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.combinations = combinations\n",
    "        self.device = device\n",
    "        self.task_IDs = []\n",
    "        self.fixed = nn.LSTM(input_size = 1,                                    #Create the fixed encoder network\n",
    "                             hidden_size = self.encoding_size,\n",
    "                             batch_first = True)\n",
    "        self.variableLSTMs = nn.ModuleDict()                                    #Create the dictionary for the variable decoder LSTM networks\n",
    "        self.variableLinears = nn.ModuleDict()                                  #Create the dictionary for the variable linear layer for the reconstruction from LSTM outputs, as done in Malhotra et al. (2016)\n",
    "        self.teacher_forcing = teacher_forcing                                  #Optionally, use teacher forcing\n",
    "        for shifting_type in self.combinations:                                 \n",
    "            for transformer_ID in self.combinations[shifting_type]:\n",
    "                combination_ID = combination_to_id(shifting_type, transformer_ID, self.combinations)\n",
    "                self.task_IDs.append(int(combination_ID))\n",
    "                self.variableLSTMs[str(combination_ID)] = nn.LSTM(input_size = 1, hidden_size = self.encoding_size, batch_first = False)\n",
    "                self.variableLinears[str(combination_ID)] = nn.Linear(self.encoding_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_id = x[:,self.sequence_length]                                        #Retrieve the column containing the combination ids\n",
    "        sort = torch.argsort(x_id)                                              #Create a sorting element that sorts the observations according to their combination id\n",
    "        reversesort = torch.argsort(sort)                                       #Create an inverse sorting element to undo the sorting at the end of the forward pass\n",
    "        x = x[sort]                                                             #Execute the sorting\n",
    "        y = []                                                                  #Create a list to save the prediction results for each id\n",
    "        ids = torch.unique(x[:,self.sequence_length], sorted = False)           #Create a list containing the ids in the batch\n",
    "        for i in ids:                                                           #Iterate over all these ids\n",
    "            x_i = x[x[:,self.sequence_length] == i]                             #Get the data from only this id\n",
    "            if x_i.shape[0] != 0:\n",
    "                combination_ID = str(int(i))                                    #Retrieve the combination ID\n",
    "                x_i = x_i[:,:self.sequence_length]                              #Discard the column containing the ids\n",
    "                x_i = x_i.unsqueeze(2)                                          #Create dimension 2: input size = 1\n",
    "                if self.teacher_forcing:\n",
    "                    transposed_x_i = torch.transpose(x_i, 0, 1)                 #Transpose the data such that it can be used as input for the batch_first = False decoder when using teacer forcing\n",
    "                _ , (h_t, c_t) = self.fixed(x_i)                                #Run the data through the encoder and retrieve the encoding\n",
    "                complete_output = torch.empty(0).to(self.device)                     #Initialize a tensor to save the decoder output\n",
    "                last_output = self.variableLinears[combination_ID](h_t)         #Initialize 0-th output directly from the encoding\n",
    "                for step in range(self.sequence_length):                        #Iterate one step at a time such that the output of the previous step can be used as input for the next\n",
    "                    last_output, (h_t, c_t) = self.variableLSTMs[combination_ID](last_output, (h_t, c_t)) #Compute the output of LSTM cell for this step\n",
    "                    last_output = self.variableLinears[combination_ID](last_output) #Compute the actual output from the LSTM output for this step\n",
    "                    complete_output = torch.cat((complete_output, last_output.squeeze(2)), dim = 0) #Add this output to the tensor that saves the decoder output\n",
    "                    if self.teacher_forcing:\n",
    "                        if self.training:                                       #When teacher forcing is enabled during the training phase, use the actual result as input for the next step\n",
    "                            last_output = transposed_x_i[-(step+1),:,:].unsqueeze(0)\n",
    "                y.append(complete_output)                                       #Add the complete output for this id to the list\n",
    "        x = torch.cat(y,1)                                                      #Concatenate the results for all ids\n",
    "        x = torch.transpose(x, 0, 1)                                            #Transpose the result to bring it in the same format as the input\n",
    "        x = x[reversesort]                                                      #Undo the sorting that was done at the start\n",
    "        x = torch.flip(x, [1])                                                  #Reconstruct the sequence in reverse order, as done in Malhotra et al. (2016)\n",
    "        return x\n",
    "    \n",
    "    def add_task(self, task_ID, shifting_type, transformer_ID, num_epochs, instances:int = 987654321, lr_schedule:bool = False, schedule_milestones = [60,90], convergence_plot:bool = True, return_training_loss:bool = True, path=\"C:\\LocalData\\Data\\Completely_preprocessed_data\"):\n",
    "        if task_ID in self.task_IDs:\n",
    "            raise ValueError(\"Task ID already used, please choose an unused task ID\")\n",
    "        self.variableLSTMs[str(task_ID)] = nn.LSTM(input_size = 1, hidden_size = self.encoding_size, batch_first = False)\n",
    "        self.variableLinears[str(task_ID)] = nn.Linear(self.encoding_size, 1)\n",
    "        ds = create_dataset({shifting_type : {transformer_ID : task_ID}}, [str(i) for i in np.arange(0,300,1)], path)\n",
    "        if instances != 987654321:\n",
    "            ds.df_torque = ds.df_torque.sample(instances, replace=True)\n",
    "        dl = torch.utils.data.DataLoader(ds, 64, True)\n",
    "        for param in self.fixed.parameters():\n",
    "            param.requires_grad = False\n",
    "        loss_function = nn.SmoothL1Loss()\n",
    "        optimizer = optim.Adam(self.variable.parameters(), 0.0001)\n",
    "        if lr_schedule:\n",
    "            scheduler = MultiStepLR(optimizer, milestones=schedule_milestones, gamma=0.1)\n",
    "        losses = []\n",
    "        for epoch in tqdm(range(num_epochs),leave=None):\n",
    "            last_losses = []\n",
    "            for data in dl:\n",
    "                data= data.to(device=device)                                        #Bring the data onto the device\n",
    "                reconstruction = self.forward(data)                                        #Execute the model\n",
    "                loss = loss_function(reconstruction, data[:,:self.sequence_length])      #Compute the loss\n",
    "                optimizer.zero_grad()                                               #Set the gradients to 0 for each batch\n",
    "                loss.backward()                                                     #Compute gradients using backpropagation\n",
    "                optimizer.step()                                                    #Execute parameter updates\n",
    "                losses.append(loss.data)\n",
    "                last_losses.append(loss.data)\n",
    "            if lr_schedule:\n",
    "                scheduler.step()\n",
    "        if convergence_plot:                                                        #Optionally plot the convergence over the iterations\n",
    "            plt.xlabel(\"Batch\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.ylim(top = 20)\n",
    "            plt.plot(torch.Tensor(losses).cpu(), linewidth = 0.2, color = \"black\")\n",
    "            plt.show()\n",
    "        self.task_IDs.append(task_ID)\n",
    "        if return_training_loss:\n",
    "            return torch.mean(torch.Tensor(losses).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"Vanilla MAE\", \"Vanilla AE\", \"TCN MAE\", \"TCN AE\", \"LSTM MAE\", \"LSTM AE\"]\n",
    "from functions.benchmark import *\n",
    "def evaluate_task_addition(combinations, sample_sizes, model, path=\"C:\\LocalData\\Data\\Completely_preprocessed_data\"):\n",
    "    resultss = []\n",
    "    for shifting_type in combinations:\n",
    "        for transformer_ID in combinations[shifting_type]:\n",
    "            test_combinations = copy.deepcopy(combinations)\n",
    "            test_combinations[shifting_type].pop(transformer_ID)\n",
    "            task_ID = combinations[shifting_type][transformer_ID]\n",
    "            if model == \"Vanilla MAE\":\n",
    "                m = Vanilla_MAE(250, 300, test_combinations, 0).to(device)\n",
    "            elif model == \"TCN MAE\":\n",
    "                m = TCN_MAE(300, test_combinations, 128, 32, 8, 6, device, 8, 32, 6).to(device)\n",
    "            elif model == \"LSTM MAE\":\n",
    "                m = LSTM_MAE(250, 300, test_combinations, device).to(device)\n",
    "            elif model == \"Vanilla AE\":\n",
    "                m = create_Vanilla_AE_separate(250, 300, {shifting_type : {transformer_ID : task_ID}}, 0, device)\n",
    "            elif model == \"TCN AE\":\n",
    "                m = create_TCN_AE_separate(300, {shifting_type : {transformer_ID : task_ID}}, 128, 32, 8, device, 8, 16, 6)\n",
    "            elif model == \"LSTM AE\":\n",
    "                m = create_LSTM_AE_separate(250, 300, {shifting_type : {transformer_ID : task_ID}}, device)\n",
    "            else:\n",
    "                print(f\"Model {model} is not implemented\")\n",
    "                break\n",
    "            if model in [\"Vanilla MAE\", \"TCN MAE\", \"LSTM MAE\"]:\n",
    "                ds = create_dataset(test_combinations, cols, path)\n",
    "                if model in [\"Vanilla MAE\", \"TCN MAE\"]:\n",
    "                    dl = create_dataloader(ds, 64, 25)\n",
    "                else:\n",
    "                    create_mixed_batch_dataloader(ds, 16)\n",
    "                train_model(m, 100, dl, train_loss_function, optimizer, device, 300, 0.0001, convergence_plot=False)\n",
    "            results = []\n",
    "            for sample_size in sample_sizes:\n",
    "                test_model = copy.deepcopy(m)\n",
    "                if model in [\"Vanilla MAE\", \"TCN MAE\", \"LSTM MAE\"]:\n",
    "                    test_model.add_task(task_ID, shifting_type, transformer_ID, 100, int(sample_size), convergence_plot=False)\n",
    "                else:\n",
    "                    ds = create_dataset({shifting_type : {transformer_ID : task_ID}}, cols, path)\n",
    "                    ds.df_torque = ds.df_torque.sample(int(sample_size))\n",
    "                    dl = torch.utils.data.DataLoader(ds, 64, True)\n",
    "                    train_model(test_model, 100, dl, nn.MSELoss, optim.Adam, device, 300, 0.0001, convergence_plot=False)\n",
    "                td = test_data[test_data['combination_ID']==task_ID]\n",
    "                result = evaluate_on_dataset(test_model, td, torch.nn.MSELoss(), shared_threshold=False, show_roc_curve=False)\n",
    "                results.append(result[0])\n",
    "            plt.plot(sample_sizes, results, scalex='log', label = str(task_ID))\n",
    "            resultss.append(results)\n",
    "    plt.legend()\n",
    "    plt.xscale('log')\n",
    "    plt.show()\n",
    "    total = []\n",
    "    for i in range(len(resultss[0])):\n",
    "        total.append(np.mean([r[i] for r in resultss]))\n",
    "    plt.plot(sample_sizes, total, scalex='log', color = 'black')\n",
    "    plt.xscale('log')\n",
    "    plt.show()\n",
    "    return total, resultss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = np.logspace(0,3,50)\n",
    "r = []\n",
    "for m in models:\n",
    "    r.append(evaluate_task_addition(combinations, sample_sizes, m))\n",
    "pickle.dump(r, open(f\"task addition results {n_tasks}.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sample_sizes, r[0][0], color = 'black', label = \"MAE\")\n",
    "plt.plot(sample_sizes, r[1][0], color = 'red', label = 'AE')\n",
    "plt.xscale(\"log\")\n",
    "plt.title(\"Vanilla\")\n",
    "plt.show()\n",
    "plt.plot(sample_sizes, r[2][0], color = 'black', label = \"MAE\")\n",
    "plt.plot(sample_sizes, r[3][0], color = 'red', label = 'AE')\n",
    "plt.xscale(\"log\")\n",
    "plt.title(\"TCN\")\n",
    "plt.show()\n",
    "plt.plot(sample_sizes, r[4][0], color = 'black', label = \"MAE\")\n",
    "plt.plot(sample_sizes, r[5][0], color = 'red', label = 'AE')\n",
    "plt.title(\"LSTM\")\n",
    "plt.xscale(\"log\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (clean)",
   "language": "python",
   "name": "clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 05:37:49) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7966d4280f7f220e705766afe74cbbb98cc757b9a51291c7a5ebca400bce06e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
